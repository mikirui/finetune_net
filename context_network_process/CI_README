context network：
googlenet模型: 
/home/qianlima/torch-test/googlenet/googlenet2.lua，即在全模型的基础上只改最后一层池化层的核为3*3，输入为3*96*96图片，输出为1024维向量.

微调代码：
/home/qianlima/torch-test/fgi_one_norm.lua

微调后模型：
/home/qianlima/save/Exia:1461484089:1.dat，文件保存的是最好的一次实验结果（dp.experiment)

用微调后模型得到每张图片CI代码：
/home/qianlima/torch-test/datapro/context_network.lua

mscoco图片CI保存文件：
/home/qianlima/ylh_test/resize_img/cocotalk384_ft_matrix.t7

修改后的dataloader:
/home/qianlima/torch-test/datapro/DataLoader.lua（改过地方均标有rui)
DataLoader:getBatch()得到data调用的域：data.images得到原图像素信息和以前一样，data.feature得到1024维特征
